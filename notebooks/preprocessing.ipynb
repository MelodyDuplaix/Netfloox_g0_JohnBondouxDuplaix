{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/all_data_for_10000_lines.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajout de la note pondérée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "\n",
    "# Paramètres pour le calcul du score pondéré\n",
    "C = df['averagerating'].mean()  # Score moyen de tous les films\n",
    "m = 1000  # Nombre minimum de votes requis pour être pris en compte\n",
    "\n",
    "# Calcul du score pondéré\n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['numvotes']\n",
    "    R = x['averagerating']\n",
    "    return (v / (v + m) * R) + (m / (v + m) * C)\n",
    "\n",
    "df['weighted_score'] = df.apply(weighted_rating, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tt12605172', 'tt12605176', 'tt12605178', 'tt1260518',\n",
       "       'tt12605180'], dtype=object)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tconst'][~df['tconst'].isna()].head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startyear</th>\n",
       "      <th>endyear</th>\n",
       "      <th>runtimeminutes</th>\n",
       "      <th>averagerating</th>\n",
       "      <th>numvotes</th>\n",
       "      <th>seasonnumber</th>\n",
       "      <th>episodenumber</th>\n",
       "      <th>regionnumber</th>\n",
       "      <th>weighted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7388.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2333.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>1027.000000</td>\n",
       "      <td>6692.000000</td>\n",
       "      <td>6692.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1027.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2007.504602</td>\n",
       "      <td>2007.130841</td>\n",
       "      <td>40.952422</td>\n",
       "      <td>6.956767</td>\n",
       "      <td>606.494645</td>\n",
       "      <td>3.455021</td>\n",
       "      <td>531.684549</td>\n",
       "      <td>4.72080</td>\n",
       "      <td>6.926801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.236246</td>\n",
       "      <td>16.892046</td>\n",
       "      <td>37.221751</td>\n",
       "      <td>1.385817</td>\n",
       "      <td>6620.788704</td>\n",
       "      <td>7.686266</td>\n",
       "      <td>1507.838716</td>\n",
       "      <td>3.46122</td>\n",
       "      <td>0.326370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1906.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.405601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>1997.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.943240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>6.959651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>6.974027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025.000000</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>177953.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>13897.000000</td>\n",
       "      <td>50.00000</td>\n",
       "      <td>8.683838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         startyear      endyear  runtimeminutes  averagerating       numvotes  \\\n",
       "count  7388.000000   107.000000     2333.000000    1027.000000    1027.000000   \n",
       "mean   2007.504602  2007.130841       40.952422       6.956767     606.494645   \n",
       "std      19.236246    16.892046       37.221751       1.385817    6620.788704   \n",
       "min    1906.000000  1951.000000        1.000000       1.100000       5.000000   \n",
       "25%    2005.000000  1997.500000       17.000000       6.300000      11.000000   \n",
       "50%    2015.000000  2015.000000       30.000000       7.200000      19.000000   \n",
       "75%    2020.000000  2020.000000       54.000000       7.900000      64.500000   \n",
       "max    2025.000000  2023.000000      435.000000      10.000000  177953.000000   \n",
       "\n",
       "       seasonnumber  episodenumber  regionnumber  weighted_score  \n",
       "count   6692.000000    6692.000000   10000.00000     1027.000000  \n",
       "mean       3.455021     531.684549       4.72080        6.926801  \n",
       "std        7.686266    1507.838716       3.46122        0.326370  \n",
       "min        1.000000       0.000000       1.00000        4.405601  \n",
       "25%        1.000000       7.000000       1.00000        6.943240  \n",
       "50%        1.000000      50.000000       3.00000        6.959651  \n",
       "75%        2.000000     335.000000       8.00000        6.974027  \n",
       "max       82.000000   13897.000000      50.00000        8.683838  "
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifier les collone numériques et Catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   tconst          10000 non-null  object \n",
      " 1   titletype       10000 non-null  object \n",
      " 2   primarytitle    10000 non-null  object \n",
      " 3   isadult         10000 non-null  bool   \n",
      " 4   startyear       7388 non-null   float64\n",
      " 5   endyear         107 non-null    float64\n",
      " 6   runtimeminutes  2333 non-null   float64\n",
      " 7   genres          9776 non-null   object \n",
      " 8   averagerating   1027 non-null   float64\n",
      " 9   numvotes        1027 non-null   float64\n",
      " 10  seasonnumber    6692 non-null   float64\n",
      " 11  episodenumber   6692 non-null   float64\n",
      " 12  regionnumber    10000 non-null  int64  \n",
      " 13  regionlist      10000 non-null  object \n",
      " 14  actor           9195 non-null   object \n",
      " 15  self            9195 non-null   object \n",
      " 16  producer        9195 non-null   object \n",
      " 17  actress         9195 non-null   object \n",
      " 18  director        9195 non-null   object \n",
      " 19  weighted_score  1027 non-null   float64\n",
      "dtypes: bool(1), float64(8), int64(1), object(10)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "\n",
    "# Les colonnes numériques identifiées sont : \n",
    "# startyear, endyear, runtimeminutes, averagerating, numvotes, seasonnumber, episodenumber, weighted_score, isadult.\n",
    "\n",
    "# Les colonnes catégorielles identifiées sont : \n",
    "# tconst, titletype, primarytitle, genres, regionlist, actor, self, producer, actress, director.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fonctions préprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\p2972\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\p2972\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#fonction de stemming\n",
    "\n",
    "def stemming(liste):\n",
    "  stemming = []\n",
    "  for element in liste:\n",
    "    elementStemme = PorterStemmer().stem(element)\n",
    "    stemming.append(elementStemme)\n",
    "  return stemming\n",
    "\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "#mettre en minuscule et supprimer les caractères spéciaux et les espaces en début et fin de texte \n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s\\[\\]]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préprocessing collone TitleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "titletype\n",
       "tvEpisode       7887\n",
       "short            821\n",
       "movie            402\n",
       "video            289\n",
       "tvSeries         271\n",
       "tvMovie          159\n",
       "tvSpecial         65\n",
       "videoGame         53\n",
       "tvMiniSeries      44\n",
       "tvShort            9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['titletype'].value_counts()\n",
    "\n",
    "# La colonne 'titletype' ne présente pas de valeurs incohérentes.\n",
    "# Elle n'a pas besoin d'être tokenisée, stemmée, ni traitée pour les stop words, \n",
    "# mais elle nécessite d'être encodée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['titletype'].value_counts()\n",
    "#Utiliser ordinal encoder pour encoder la colonne titletype\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "OrdinalEncoder_titletype = encoder.fit_transform(df['titletype'].values.reshape(-1, 1)) #reshape(-1, 1) pour convertir une liste en tableau\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préprocessing collone Primarytitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Episode #1.2', 'Shaheb Bibi Golam', 'Girl in the Mirror',\n",
       "       'Loose Ends', 'Episode #1.3'], dtype=object)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['primarytitle'].head().values\n",
    "\n",
    "# On remarque que les titres sont variés et ne se ressemblent pas. Une tokenisation est donc nécessaire.\n",
    "\n",
    "# Les stop words ne doivent pas être supprimés, car cela pourrait altérer le sens des titres.\n",
    "# Certains titres sont définis par leurs stop words, par exemple : \"The Walking Dead\" ou \"The Good Place\".\n",
    "\n",
    "# Un stemming est recommandé. Par exemple, si un utilisateur apprécie un film contenant le mot \"run\", \n",
    "# le stemming ou la lemmatisation permettra de faire correspondre ce mot avec d'autres variantes telles que \"running\" ou \"runs\". \n",
    "# Cela améliore la qualité des recommandations basées sur la similitude des titres.\n",
    "\n",
    "# Pour un système simple basé sur la présence ou l'absence de mots, le TF-IDF peut être approprié.\n",
    "# Il représente chaque titre en fonction des mots qu'il contient, avec un poids plus élevé pour les mots rares et significatifs.\n",
    "# Cela peut aider à identifier les mots associés aux meilleures notes, analyser leur influence, ou améliorer la gestion des titres similaires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collone primarytitle\n",
    "\n",
    "#Stemming\n",
    "df['primarytitle_processed'] = df['primarytitle'].apply(stemming)\n",
    "\n",
    "#Retirer caractères spéciaux, espaces et retourner en minuscule\n",
    "df['primarytitle_processed'] = df['primarytitle'].apply(clean_text)\n",
    "\n",
    "#Tokenization\n",
    "df['primarytitle_processed'] = df['primarytitle_processed'].apply(lambda x : x.split())\n",
    "\n",
    "df[['primarytitle_processed','primarytitle']].head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Rejointure des tokens en une chaîne de texte\n",
    "df['primarytitle_processed'] = df['primarytitle_processed'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# 1. Initialisation de TfidfVectorizer et vectorisation\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(df['primarytitle_processed'])\n",
    "\n",
    "# 2. Conversion de la matrice TF-IDF en DataFrame avec préfixe\n",
    "tfidf_df_primary_title = pd.DataFrame(tfidf_matrix.toarray(), columns=['tfidf_' + word for word in vectorizer.get_feature_names_out()])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing collone genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             Action,Mystery\n",
       "1                      Drama\n",
       "2                Music,Short\n",
       "3                      Drama\n",
       "4             Action,Mystery\n",
       "                ...         \n",
       "9995    Crime,Drama,Thriller\n",
       "9996               Adventure\n",
       "9997                   Drama\n",
       "9998                   Adult\n",
       "9999                  Sci-Fi\n",
       "Name: genres, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genres\n",
       "Drama                    2203\n",
       "Talk-Show                 722\n",
       "Comedy                    598\n",
       "Documentary               537\n",
       "Reality-TV                425\n",
       "                         ... \n",
       "Crime,Horror,Mystery        1\n",
       "Action,Comedy,Fantasy       1\n",
       "Reality-TV,Sport            1\n",
       "Action,Drama,Mystery        1\n",
       "Horror,Mystery              1\n",
       "Name: count, Length: 354, dtype: int64"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genres'].value_counts()\n",
    "\n",
    "# On observe 354 combinaisons de genres différentes.\n",
    "# Il est nécessaire de les tokeniser, et de les encoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>titletype</th>\n",
       "      <th>primarytitle</th>\n",
       "      <th>isadult</th>\n",
       "      <th>startyear</th>\n",
       "      <th>endyear</th>\n",
       "      <th>runtimeminutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>averagerating</th>\n",
       "      <th>numvotes</th>\n",
       "      <th>...</th>\n",
       "      <th>episodenumber</th>\n",
       "      <th>regionnumber</th>\n",
       "      <th>regionlist</th>\n",
       "      <th>actor</th>\n",
       "      <th>self</th>\n",
       "      <th>producer</th>\n",
       "      <th>actress</th>\n",
       "      <th>director</th>\n",
       "      <th>weighted_score</th>\n",
       "      <th>primarytitle_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>tt1260526</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Hank Williams Jr.</td>\n",
       "      <td>False</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>['\\\\N']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Steven North']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hank williams jr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>tt1260527</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Ricky Nelson</td>\n",
       "      <td>False</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>['\\\\N']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Ricky Nelson']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Steven North']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ricky nelson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>tt1260544</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Episode #1.16</td>\n",
       "      <td>False</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Juha Helppi', 'Robin Keston', 'Dave Mattey',...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>episode 116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>tt12605676</td>\n",
       "      <td>tvSeries</td>\n",
       "      <td>CBC News: At Issue</td>\n",
       "      <td>False</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>['\\\\N', 'CA']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Althia Raj', 'Althia Raj', 'Rosemary Barton'...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>6.933433</td>\n",
       "      <td>cbc news at issue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>tt12605782</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Episode #1.11</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>episode 111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9743</th>\n",
       "      <td>tt12623656</td>\n",
       "      <td>tvMovie</td>\n",
       "      <td>A tocar!</td>\n",
       "      <td>False</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>['\\\\N', 'ES']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Camille Decourtye', 'Frederic Amat', 'Blaï M...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Camille Decourtye', 'Blaï Mateu']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a tocar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>tt1262377</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Episode #1.7</td>\n",
       "      <td>False</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']</td>\n",
       "      <td>['David Ramírez', 'Toni Mora']</td>\n",
       "      <td>['Jordi Borràs', 'Carles Rexach', 'Anna Llache...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Òscar Lorca', 'Mai Balaguer']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>episode 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9801</th>\n",
       "      <td>tt1262378</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Episode #5.40</td>\n",
       "      <td>False</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Susanna Griso', 'Ferran Monegal']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Ferran Monegal']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>episode 540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>tt12623922</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Episode dated 1 August 2005</td>\n",
       "      <td>False</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['José Miguel Viñuela', 'Jessica Cirio', 'Thia...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>episode dated 1 august 2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9897</th>\n",
       "      <td>tt1262399</td>\n",
       "      <td>tvEpisode</td>\n",
       "      <td>Episode #1.1</td>\n",
       "      <td>False</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Paola Cano', 'Natalia Duran']</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>episode 11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tconst  titletype                 primarytitle  isadult  startyear  \\\n",
       "36     tt1260526  tvEpisode            Hank Williams Jr.    False     1979.0   \n",
       "41     tt1260527  tvEpisode                 Ricky Nelson    False     1979.0   \n",
       "127    tt1260544  tvEpisode                Episode #1.16    False     2008.0   \n",
       "236   tt12605676   tvSeries           CBC News: At Issue    False     2007.0   \n",
       "291   tt12605782  tvEpisode                Episode #1.11    False     2020.0   \n",
       "...          ...        ...                          ...      ...        ...   \n",
       "9743  tt12623656    tvMovie                     A tocar!    False     2020.0   \n",
       "9797   tt1262377  tvEpisode                 Episode #1.7    False     2008.0   \n",
       "9801   tt1262378  tvEpisode                Episode #5.40    False     2008.0   \n",
       "9864  tt12623922  tvEpisode  Episode dated 1 August 2005    False     2005.0   \n",
       "9897   tt1262399  tvEpisode                 Episode #1.1    False     2008.0   \n",
       "\n",
       "      endyear  runtimeminutes genres  averagerating  numvotes  ...  \\\n",
       "36        NaN             NaN    NaN            NaN       NaN  ...   \n",
       "41        NaN             NaN    NaN            NaN       NaN  ...   \n",
       "127       NaN            90.0    NaN            NaN       NaN  ...   \n",
       "236       NaN            30.0    NaN            3.6       7.0  ...   \n",
       "291       NaN            21.0    NaN            NaN       NaN  ...   \n",
       "...       ...             ...    ...            ...       ...  ...   \n",
       "9743      NaN             NaN    NaN            NaN       NaN  ...   \n",
       "9797      NaN             NaN    NaN            NaN       NaN  ...   \n",
       "9801      NaN             NaN    NaN            NaN       NaN  ...   \n",
       "9864      NaN             NaN    NaN            NaN       NaN  ...   \n",
       "9897      NaN             NaN    NaN            NaN       NaN  ...   \n",
       "\n",
       "      episodenumber  regionnumber  \\\n",
       "36              NaN             1   \n",
       "41              NaN             1   \n",
       "127            16.0             8   \n",
       "236             NaN             2   \n",
       "291            11.0             8   \n",
       "...             ...           ...   \n",
       "9743            NaN             2   \n",
       "9797            7.0             8   \n",
       "9801           40.0             8   \n",
       "9864            NaN             8   \n",
       "9897            1.0             8   \n",
       "\n",
       "                                             regionlist  \\\n",
       "36                                              ['\\\\N']   \n",
       "41                                              ['\\\\N']   \n",
       "127   ['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']   \n",
       "236                                       ['\\\\N', 'CA']   \n",
       "291   ['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']   \n",
       "...                                                 ...   \n",
       "9743                                      ['\\\\N', 'ES']   \n",
       "9797  ['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']   \n",
       "9801  ['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']   \n",
       "9864  ['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']   \n",
       "9897  ['\\\\N', 'PT', 'IN', 'FR', 'IT', 'DE', 'JP', 'ES']   \n",
       "\n",
       "                               actor  \\\n",
       "36                                []   \n",
       "41                                []   \n",
       "127                               []   \n",
       "236                               []   \n",
       "291                              NaN   \n",
       "...                              ...   \n",
       "9743                              []   \n",
       "9797  ['David Ramírez', 'Toni Mora']   \n",
       "9801                              []   \n",
       "9864                              []   \n",
       "9897                              []   \n",
       "\n",
       "                                                   self producer  \\\n",
       "36                                                   []       []   \n",
       "41                                     ['Ricky Nelson']       []   \n",
       "127   ['Juha Helppi', 'Robin Keston', 'Dave Mattey',...       []   \n",
       "236   ['Althia Raj', 'Althia Raj', 'Rosemary Barton'...       []   \n",
       "291                                                 NaN      NaN   \n",
       "...                                                 ...      ...   \n",
       "9743  ['Camille Decourtye', 'Frederic Amat', 'Blaï M...       []   \n",
       "9797  ['Jordi Borràs', 'Carles Rexach', 'Anna Llache...       []   \n",
       "9801                ['Susanna Griso', 'Ferran Monegal']       []   \n",
       "9864  ['José Miguel Viñuela', 'Jessica Cirio', 'Thia...       []   \n",
       "9897                                                 []       []   \n",
       "\n",
       "                              actress                             director  \\\n",
       "36                                 []                     ['Steven North']   \n",
       "41                                 []                     ['Steven North']   \n",
       "127                                []                                   []   \n",
       "236                                []                                   []   \n",
       "291                               NaN                                  NaN   \n",
       "...                               ...                                  ...   \n",
       "9743                               []  ['Camille Decourtye', 'Blaï Mateu']   \n",
       "9797                               []      ['Òscar Lorca', 'Mai Balaguer']   \n",
       "9801                               []                   ['Ferran Monegal']   \n",
       "9864                               []                                   []   \n",
       "9897  ['Paola Cano', 'Natalia Duran']                                   []   \n",
       "\n",
       "     weighted_score       primarytitle_processed  \n",
       "36              NaN             hank williams jr  \n",
       "41              NaN                 ricky nelson  \n",
       "127             NaN                  episode 116  \n",
       "236        6.933433            cbc news at issue  \n",
       "291             NaN                  episode 111  \n",
       "...             ...                          ...  \n",
       "9743            NaN                      a tocar  \n",
       "9797            NaN                   episode 17  \n",
       "9801            NaN                  episode 540  \n",
       "9864            NaN  episode dated 1 august 2005  \n",
       "9897            NaN                   episode 11  \n",
       "\n",
       "[224 rows x 21 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['genres'].apply(lambda x : type(x)).value_counts() #On compte les données de type str\n",
    "\n",
    "df[df['genres'].apply(lambda x: isinstance(x, float))] #On vérifie les valeurs nulles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], shape=(10000, 28))"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Créer une copie de la colonne 'genres' pour le traitement\n",
    "df['genres_processed'] = df['genres']\n",
    "\n",
    "# 2. Supprimer les valeurs de type float en convertissant en chaîne de caractères\n",
    "df['genres_processed'] = df['genres_processed'].astype(str)\n",
    "\n",
    "# 3. Analyser les genres : compter les occurrences de chaque genre individuel\n",
    "df['genres_processed'].apply(lambda x: x.split(',')).explode().value_counts()\n",
    "\n",
    "# 4. Appliquer MultiLabelBinarizer sur la colonne 'genres_processed'\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Initialisation du binariseur\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "# Conversion de la colonne en listes de genres\n",
    "df['genres_processed'] = df['genres_processed'].apply(lambda x: x.split(','))\n",
    "\n",
    "# Appliquer le MultiLabelBinarizer pour créer une matrice binaire\n",
    "multilabel = mlb.fit_transform(df['genres_processed'])\n",
    "\n",
    "\n",
    "multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
